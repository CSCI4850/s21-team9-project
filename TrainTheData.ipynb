{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flying-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from IPython.display import display\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "%matplotlib inline\n",
    "#import face_recognition\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#global variables of the picture size\n",
    "IMAGESIZE = [299, 299]  # width (0) Height (1) Images are resized to the this before getting push to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reverse-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460594   62328\n"
     ]
    }
   ],
   "source": [
    "# load up the meta data Image paths \n",
    "imdb_jsonFile = json.load(open(\"imdb_outputdata.json\"))\n",
    "wiki_jsonFile = json.load(open(\"wiki_outputdata.json\"))\n",
    "imdb_file_location = '../imdb/'\n",
    "wiki_file_location = '../wiki/'\n",
    "imdbLen = len(imdb_jsonFile)\n",
    "wikiLen = len(wiki_jsonFile)\n",
    "print(imdbLen, \" \", wikiLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opened-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage print(get_face_locations('nm0000001_rm946909184_1899-5-10_1968.jpg'))\n",
    "def get_face_locations(imagePath): \n",
    "    image = face_recognition.load_image_file(imagePath)\n",
    "    return face_recognition.face_locations(image)\n",
    "\n",
    "# crop the image to just read the face location  \n",
    "def crop_image(image, face_loc):\n",
    "    return image[face_loc[1]:face_loc[3], face_loc[0]:face_loc[2]]  #  1 , 3, 0, 2\n",
    "\n",
    "# resize the image to match the \n",
    "def resize_image(image):\n",
    "    dsize = (IMAGESIZE[0], IMAGESIZE[1]) # width (0) Height (1)  \n",
    "    return cv2.resize(image, dsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "binding-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the base gender model                                  \n",
    "def gender_model(X,Y):\n",
    "    base_model = keras.applications.Xception(weights='imagenet',include_top=False)\n",
    "    new_model = base_model.output\n",
    "    new_model = keras.layers.GlobalAveragePooling2D()(new_model)\n",
    "    new_model = keras.layers.Dense(128,activation='relu')(new_model)\n",
    "    new_model = keras.layers.Dense(Y.shape[1],activation='softmax')(new_model)\n",
    "    model = keras.Model(inputs=base_model.input,outputs=new_model)\n",
    "    model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "             metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "    model.summary()\n",
    "    return model         \n",
    "#get the base age model                                   \n",
    "def age_model(X,Y):\n",
    "    base_model = keras.applications.Xception(weights='imagenet',include_top=False)\n",
    "    new_model = base_model.output\n",
    "    new_model = keras.layers.GlobalAveragePooling2D()(new_model)\n",
    "    new_model = keras.layers.Dense(128,activation='relu')(new_model)\n",
    "    new_model = keras.layers.Dense(Y.shape[1],activation='softmax')(new_model)\n",
    "    model = keras.Model(inputs=base_model.input,outputs=new_model)\n",
    "    model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "             metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "    model.summary()\n",
    "    return model                                \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exciting-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to  fetch the IMAGES from X(start) to Y(end) and returns three arrays  \n",
    "def read_images_gender_Age(start, end, JSON_File, images_location):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    Z=[]\n",
    "    corrupted_entry = 0 \n",
    "    corrupted_age = 0 \n",
    "    undetected_faces = 0\n",
    "    for x in range(start, end):\n",
    "        try:\n",
    "            image = cv2.imread(images_location+JSON_File[x][3])    \n",
    "                # if the image is one of the corrupted image, skip this entry \n",
    "            if(image is None or image.shape == (47,100,3) or image.shape == (1,1,3) or JSON_File[x][0] == \"nan\"):\n",
    "                corrupted_entry +=1 \n",
    "                continue\n",
    "            face_loc = JSON_File[x][2]\n",
    "            cropped_image = crop_image(image, face_loc)\n",
    "            resized_image = resize_image(cropped_image)\n",
    "            X.append(resized_image)\n",
    "            Y.append(JSON_File[x][0]) # gender \n",
    "            Z.append(int(JSON_File[x][1])//5) # age\n",
    "            #print(resized_image.shape)\n",
    "            #plt.imshow(resized_image) \n",
    "            #plt.show()\n",
    "            if(x % 1000 == 0):\n",
    "                print('read one 1000')\n",
    "        except Exception as e:\n",
    "            print('ran into exception, skipping this photo entry, Error:', e)\n",
    "            continue\n",
    "            \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).astype('float32')\n",
    "    Y = keras.utils.to_categorical(Y)\n",
    "    Z = np.array(Z).astype('float32')\n",
    "    Z = keras.utils.to_categorical(Z, num_classes = 26)\n",
    "    print('Read from ', start, ' to ', end, '. There were ',corrupted_entry)\n",
    "    return X,Y,Z\n",
    "\n",
    "#                       ['00','01','02','03','04','05']  \n",
    "def read_images_byfile(files, JSON_File, images_location):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    Z=[]\n",
    "    corrupted_entry = 0 \n",
    "    corrupted_age = 0 \n",
    "    undetected_faces = 0\n",
    "    count =0 \n",
    "    for x in range(len(JSON_File)):\n",
    "        if ((JSON_File[x][3]).split(\"/\")[0] in files):\n",
    "            try:\n",
    "                image = cv2.imread(images_location+JSON_File[x][3])\n",
    "                \n",
    "                    # if the image is one of the corrupted image, skip this entry \n",
    "                if(image is None or image.shape == (47,100,3) or image.shape == (1,1,3) or JSON_File[x][0] == \"nan\"):\n",
    "                    corrupted_entry +=1 \n",
    "                    continue\n",
    "                face_loc = JSON_File[x][2]\n",
    "                cropped_image = crop_image(image, face_loc)\n",
    "                resized_image = resize_image(cropped_image)\n",
    "                X.append(resized_image)\n",
    "                Y.append(JSON_File[x][0]) # gender \n",
    "                Z.append(int(JSON_File[x][1])//5) # age\n",
    "                count +=1\n",
    "                \n",
    "                if(count % 1000 == 0):\n",
    "                    print('read one 1000')\n",
    "            except Exception as e:\n",
    "                print('ran into exception, skipping this photo entry, Error:', e)\n",
    "                continue\n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).astype('float32')\n",
    "    Y = keras.utils.to_categorical(Y)\n",
    "    Z = np.array(Z).astype('float32')\n",
    "    Z = keras.utils.to_categorical(Z, num_classes = 26)\n",
    "    print('read_images_by_file read', count, 'images')\n",
    "    print('read these files' , str(files),'There were ',corrupted_entry')\n",
    "    return X,Y,Z\n",
    "\n",
    "\n",
    "#store the model and the history and which data entries were processed \n",
    "def store_history_model(model, history, start, end, duration, historyFilelocation, model_name, dataSetName):\n",
    "    try:\n",
    "        try:\n",
    "            json_object = json.load(open(historyFilelocation))\n",
    "        except:\n",
    "            json_object = []\n",
    "\n",
    "        storage_file = open(historyFilelocation, 'w')\n",
    "\n",
    "        h5filename = str(start) + '-' + str(end)+ model_name + \"-\" + str(dataSetName)+ '.h5'\n",
    "        h5_location = \"./\" + model_name + \"/\" + h5filename;\n",
    "\n",
    "        model.save(h5_location);\n",
    "\n",
    "        json_object.append({\"h5Filename\": h5filename,\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"duration\": duration,\n",
    "                \"h5_location\": h5_location, \n",
    "                \"categorical_accuracy\": str(history.history['categorical_accuracy']),          \n",
    "                \"val_categorical_accuracy\": str(history.history['val_categorical_accuracy']),          \n",
    "                \"loss\": str(history.history['loss']),\n",
    "                \"val_loss\": str(history.history['val_loss'])\n",
    "                           })\n",
    "\n",
    "        json.dump(json_object, storage_file)\n",
    "        storage_file.close()\n",
    "    except Exception as e:\n",
    "        print('ran into exception while trying to store model after fitting for index ', start, ' to index ', end, ' , Error:', e)\n",
    "        return 0\n",
    "    \n",
    "    return 1\n",
    "def store_history_model_byFiles(model, history, files, duration, historyFilelocation, model_name, dataSetName):\n",
    "    try:\n",
    "        try:\n",
    "            json_object = json.load(open(historyFilelocation))\n",
    "        except:\n",
    "            json_object = []\n",
    "\n",
    "        storage_file = open(historyFilelocation, 'w')\n",
    "\n",
    "        h5filename = str(files)+ model_name + \"-\" + str(dataSetName)+ '.h5'\n",
    "        h5_location = \"./\" + model_name + \"/\" + h5filename;\n",
    "\n",
    "        model.save(h5_location);\n",
    "\n",
    "        json_object.append({\"h5Filename\": h5filename,\n",
    "                \"files\": str(files),\n",
    "                \"duration\": duration,\n",
    "                \"h5_location\": h5_location, \n",
    "                \"categorical_accuracy\": str(history.history['categorical_accuracy']),          \n",
    "                \"val_categorical_accuracy\": str(history.history['val_categorical_accuracy']),          \n",
    "                \"loss\": str(history.history['loss']),\n",
    "                \"val_loss\": str(history.history['val_loss'])\n",
    "                           })\n",
    "\n",
    "        json.dump(json_object, storage_file)\n",
    "        storage_file.close()\n",
    "    except Exception as e:\n",
    "        print('ran into exception while trying to store model Error:', e)\n",
    "        return 0\n",
    "    \n",
    "    return 1\n",
    "\n",
    "# pull the latest model checkpoint    \n",
    "def pull_latest_model(historyFilelocation):\n",
    "    try:\n",
    "        json_object = json.load(open(historyFilelocation))\n",
    "    except Exception as e:\n",
    "        print('could not get the latest model, Error:', e)\n",
    "        return 0\n",
    "    print('trying to load model from', json_object[len(json_object)-1]['h5_location'])\n",
    "    return keras.models.load_model(json_object[len(json_object)-1]['h5_location'])\n",
    "\n",
    "\n",
    "def fit_model(model, X, Y, num_epochs):\n",
    "    batch_size = 40\n",
    "    epochs = num_epochs\n",
    "    validation_split = 0.2\n",
    "    history = model.fit(X, Y,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=2,\n",
    "                    validation_split = validation_split)\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_gender_model(start, end, JSON_FILE, images_location, historyFile, dataSetName):\n",
    "    try:\n",
    "        print('Training gender model')\n",
    "        start_time = time.time()\n",
    "        X,Y,Z = read_images_gender_Age(start, end, JSON_FILE, images_location) #\"../imdb/\"\n",
    "        latest_gender_model =  pull_latest_model(historyFile)  # \"./genderHistory.json\"\n",
    "        if(latest_gender_model == 0):\n",
    "            print(\"couldn't find a stored model, generating a new one\")\n",
    "            latest_gender_model = gender_model(X,Y)\n",
    "        else:\n",
    "            print(\"Found previously stored model from \", historyFile)\n",
    "        \n",
    "        history = fit_model(latest_gender_model, X, Y, 1)\n",
    "        duration = (time.time() - start_time)\n",
    "        store_history_model(latest_gender_model,history,start,end,duration,historyFile,'gender',dataSetName)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print('ran into exception while training index ', start, ' to index ', end, ' did not train this set, Error:', e)\n",
    "        return 0\n",
    "        \n",
    "    return X,Y,Z\n",
    "\n",
    "def train_age_model(start, end, JSON_FILE, images_location, historyFile, dataSetName):\n",
    "    try:\n",
    "        print('Training age model')\n",
    "        start_time = time.time()\n",
    "        X,Y,Z = read_images_gender_Age(start, end, JSON_FILE, images_location) #\"../imdb/\"\n",
    "        latest_age_model =  pull_latest_model(historyFile)  # \"./genderHistory.json\"\n",
    "        if(latest_age_model == 0):\n",
    "            print(\"couldn't find a stored model, generating a new one\")\n",
    "            latest_age_model = age_model(X,Z)\n",
    "        else:\n",
    "            print(\"Found previously stored model from \", historyFile)\n",
    "        \n",
    "        history = fit_model(latest_age_model, X, Z, 2)\n",
    "        duration = (time.time() - start_time)\n",
    "        store_history_model(latest_age_model,history,start,end,duration,historyFile,'age',dataSetName)\n",
    "          \n",
    "    except Exception as e:\n",
    "        print('ran into exception while training index ', start, ' to index ', end, ' did not train this set, Error:', e)\n",
    "        return 0\n",
    "        \n",
    "    return X,Y,Z \n",
    "\n",
    "def train_gender_model_byfile(files, JSON_FILE, images_location, historyFile, dataSetName):\n",
    "    try:\n",
    "        print('Training gender model')\n",
    "        start_time = time.time()\n",
    "        X,Y,Z = read_images_byfile(files, JSON_FILE, images_location) #\"../imdb/\"\n",
    "        latest_gender_model =  pull_latest_model(historyFile)  # \"./genderHistory.json\"\n",
    "        if(latest_gender_model == 0):\n",
    "            print(\"couldn't find a stored model, generating a new one\")\n",
    "            latest_gender_model = gender_model(X,Y)\n",
    "        else:\n",
    "            print(\"Found previously stored model from \", historyFile)\n",
    "        \n",
    "        history = fit_model(latest_gender_model, X, Y, 1)\n",
    "        duration = (time.time() - start_time)\n",
    "        store_history_model_byFiles(latest_gender_model,history,files,duration,historyFile,'gender',dataSetName)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print('ran into exception while training did not train this set, Error:', e)\n",
    "        return 0\n",
    "        \n",
    "    return X,Y,Z \n",
    "\n",
    "def train_age_model_byfile(files, JSON_FILE, images_location, historyFile, dataSetName):\n",
    "    try:\n",
    "        print('Training age model')\n",
    "        start_time = time.time()\n",
    "        X,Y,Z = read_images_byfile(files, JSON_FILE, images_location) #\"../imdb/\"\n",
    "        latest_age_model =  pull_latest_model(historyFile)  # \"./genderHistory.json\"\n",
    "        if(latest_age_model == 0):\n",
    "            print(\"couldn't find a stored model, generating a new one\")\n",
    "            latest_age_model = age_model(X,Z)\n",
    "        else:\n",
    "            print(\"Found previously stored model from \", historyFile)\n",
    "            \n",
    "        history = fit_model(latest_age_model, X, Z, 2)\n",
    "        duration = (time.time() - start_time)\n",
    "        store_history_model_byFiles(latest_age_model,history,files,duration,historyFile,'age',dataSetName)\n",
    "          \n",
    "    except Exception as e:\n",
    "        print('ran into exception while training did not train this set, Error:', e)\n",
    "        return 0\n",
    "        \n",
    "    return X,Y,Z \n",
    "\n",
    "#fetch the last 20 percent from the imdb(368,475  --  92,119) & wiki(49,862 --- 12,466) data sets, and run model.predict and see what's the accuracy rate.     \n",
    "def test_model():\n",
    "    \n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "verbal-japanese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training age model\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read_images_by_file read 26334 images\n",
      "read these files ['35', '36', '37', '38', '39', '40'] There were  310  corrupted entries avoided, also avoided corrupted 0 age entries, also  4069  undetected faces skip\n",
      "trying to load model from ./age/0-62328age-wikidataset2.h5\n",
      "ran into exception while training did not train this set, Error: SavedModel file does not exist at: ./age/0-62328age-wikidataset2.h5/{saved_model.pbtxt|saved_model.pb}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-57742d7791ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_age_model_byfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"35\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"36\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"37\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"38\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"39\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"40\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_jsonFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../imdb/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./ageHistory2.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IMDB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "X,Y,Z = train_age_model_byfile([\"35\",\"36\",\"37\",\"38\",\"39\",\"40\"], imdb_jsonFile, \"../imdb/\", \"./ageHistory2.json\", \"IMDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "million-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "Read from  40000  to  49862 . There were  1710  corrupted entries avoided, also avoided corrupted 5 age entries\n",
      "Found previously stored model\n",
      "  2/261 [..............................] - ETA: 37s - loss: 0.5586 - categorical_accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0263s vs `on_train_batch_end` time: 0.1261s). Check your callbacks.\n",
      "261/261 [==============================] - 43s 164ms/step - loss: 0.5486 - categorical_accuracy: 0.7649 - val_loss: 0.5511 - val_categorical_accuracy: 0.7601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gender_model(40000, 49862, wiki_jsonFile, \"../wiki/\", \"./genderHistory.json\", \"wikidataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-humidity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training age model\n",
      "read_images_by_file read 489 images\n",
      "There were  110  corrupted entries avoided, also avoided corrupted 1 age entries\n",
      "could not get the latest model, Error: [Errno 2] No such file or directory: './ageHistory.json'\n",
      "couldn't find a stored model, generating a new one\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 1 512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 2 32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 2 1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 7 186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 7 2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 1 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 1 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          262272      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 130)          16770       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,157,034\n",
      "Trainable params: 21,102,506\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/4\n"
     ]
    }
   ],
   "source": [
    "train_age_model_byfile([\"00\"], wiki_jsonFile, \"./\", \"./ageHistory.json\", \"wikidataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "canadian-planning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 199, 199, 64)      832       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 128)     32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 99, 99, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 99, 99, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1254528)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               160579712 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 160,630,210\n",
      "Trainable params: 160,630,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(2, 2),\n",
    " activation='relu',\n",
    " input_shape=[X.shape[1],\n",
    " X.shape[2],\n",
    " X.shape[3]]))\n",
    "model.add(keras.layers.Conv2D(128, (2, 2), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(Y.shape[1], activation='softmax'))\n",
    "model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    " optimizer=keras.optimizers.Adam(),\n",
    " metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "model.summary()\n",
    "\n",
    "batch_size = 25\n",
    "epochs = 10\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-excitement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "stretch-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicitions  = model.predict(X[:,:,:,:])\n",
    "men_classified_as_women = []\n",
    "women_classified_as_men = []\n",
    "for x in range(len(Y)):\n",
    "    if(float(Y[x][1]) == 1.0 and float(predicitions[x][1]) < 0.5):\n",
    "        men_classified_as_women.append(x)\n",
    "        \n",
    "for x in range(len(Y)):\n",
    "    if(float(Y[x][0]) == 1.0 and float(predicitions[x][0]) < 0.5):\n",
    "        women_classified_as_men.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('men_classified_as_women ', len(men_classified_as_women))\n",
    "print('women_classified_as_men ',  len(women_classified_as_men))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(women_classified_as_men)):\n",
    "    print('showing Image at index -', women_classified_as_men[x])\n",
    "    print(Y[women_classified_as_men[x]])\n",
    "    print(predicitions[women_classified_as_men[x]])\n",
    "    plt.imshow(X[women_classified_as_men[x],:,:,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-tyler",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ready-westminster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['00', '01', '02', '03', '04', '05']\""
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "files = ['00','01','02','03','04','05']\n",
    "\n",
    "name = '01/nm0000001_rm124825600_1899-5-10_1968.jpg'\n",
    "\n",
    "str(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-basic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-energy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
