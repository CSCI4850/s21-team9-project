{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from IPython.display import display\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "%matplotlib inline\n",
    "#import face_recognition\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#global variables of the picture size\n",
    "IMAGESIZE = [299, 299]  # width (0) Height (1) Images are resized to the this before getting push to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398305   44298\n"
     ]
    }
   ],
   "source": [
    "# load up the meta data Image paths \n",
    "imdb_jsonFile = json.load(open(\"imdb_outputdata.json\"))\n",
    "wiki_jsonFile = json.load(open(\"wiki_outputdata.json\"))\n",
    "imdb_file_location = '../imdb/'\n",
    "wiki_file_location = '../wiki/'\n",
    "imdbLen = len(imdb_jsonFile)\n",
    "wikiLen = len(wiki_jsonFile)\n",
    "print(imdbLen, \" \", wikiLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage print(get_face_locations('nm0000001_rm946909184_1899-5-10_1968.jpg'))\n",
    "def get_face_locations(imagePath): \n",
    "    image = face_recognition.load_image_file(imagePath)\n",
    "    return face_recognition.face_locations(image)\n",
    "\n",
    "# crop the image to just read the face location  \n",
    "def crop_image(image, face_loc):\n",
    "    return image[face_loc[1]:face_loc[3], face_loc[0]:face_loc[2]]  #  1 , 3, 0, 2\n",
    "\n",
    "# resize the image to match the \n",
    "def resize_image(image):\n",
    "    dsize = (IMAGESIZE[0], IMAGESIZE[1]) # width (0) Height (1)  \n",
    "    return cv2.resize(image, dsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the base gender model                                  \n",
    "def gender_model(X,Y):\n",
    "    base_model = keras.applications.Xception(weights='imagenet',include_top=False)\n",
    "    new_model = base_model.output\n",
    "    new_model = keras.layers.GlobalAveragePooling2D()(new_model)\n",
    "    new_model = keras.layers.Dense(128,activation='relu')(new_model)\n",
    "    new_model = keras.layers.Dense(Y.shape[1],activation='softmax')(new_model)\n",
    "    model = keras.Model(inputs=base_model.input,outputs=new_model)\n",
    "    model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "             metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "    model.summary()\n",
    "    return model         \n",
    "#get the base age model                                   \n",
    "def age_model(X,Y):\n",
    "    base_model = keras.applications.Xception(weights='imagenet',include_top=False)\n",
    "    new_model = base_model.output\n",
    "    new_model = keras.layers.GlobalAveragePooling2D()(new_model)\n",
    "    new_model = keras.layers.Dense(128,activation='relu')(new_model)\n",
    "    new_model = keras.layers.Dense(Y.shape[1],activation='softmax')(new_model)\n",
    "    model = keras.Model(inputs=base_model.input,outputs=new_model)\n",
    "    model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "             metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "    model.summary()\n",
    "    return model                                \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to  fetch the IMAGES from X(start) to Y(end) and returns three arrays  \n",
    "def read_images_gender_Age(start, end, JSON_File, images_location):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    Z=[]\n",
    "    corrupted_entry = 0 \n",
    "    corrupted_age = 0 \n",
    "    undetected_faces = 0\n",
    "    for x in range(start, end):\n",
    "        try:\n",
    "            image = cv2.imread(images_location+JSON_File[x][3])    \n",
    "                # if the image is one of the corrupted image, skip this entry \n",
    "            if(image is None or image.shape == (47,100,3) or image.shape == (1,1,3) or JSON_File[x][0] == \"nan\"):\n",
    "                corrupted_entry +=1 \n",
    "                continue\n",
    "            face_loc = JSON_File[x][2]\n",
    "            cropped_image = crop_image(image, face_loc)\n",
    "            resized_image = resize_image(cropped_image)\n",
    "            X.append(resized_image)\n",
    "            Y.append(JSON_File[x][0]) # gender \n",
    "            Z.append(int(JSON_File[x][1])//5) # age\n",
    "            #print(resized_image.shape)\n",
    "            #plt.imshow(resized_image) \n",
    "            #plt.show()\n",
    "            if(x % 1000 == 0):\n",
    "                print('read one 1000')\n",
    "        except Exception as e:\n",
    "            print('ran into exception, skipping this photo entry, Error:', e)\n",
    "            continue\n",
    "            \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).astype('float32')\n",
    "    Y = keras.utils.to_categorical(Y)\n",
    "    Z = np.array(Z).astype('float32')\n",
    "    Z = keras.utils.to_categorical(Z, num_classes = 26)\n",
    "    print('Read from ', start, ' to ', end, '. There were ',corrupted_entry)\n",
    "    return X,Y,Z\n",
    "\n",
    "#                       ['00','01','02','03','04','05']  \n",
    "def read_images_byfile(files, JSON_File, images_location):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    Z=[]\n",
    "    corrupted_entry = 0 \n",
    "    corrupted_age = 0 \n",
    "    undetected_faces = 0\n",
    "    count =0 \n",
    "    for x in range(len(JSON_File)):\n",
    "        if ((JSON_File[x][3]).split(\"/\")[0] in files):\n",
    "            try:\n",
    "                image = cv2.imread(images_location+JSON_File[x][3])\n",
    "                \n",
    "                    # if the image is one of the corrupted image, skip this entry \n",
    "                if(image is None or image.shape == (47,100,3) or image.shape == (1,1,3) or JSON_File[x][0] == \"nan\"):\n",
    "                    corrupted_entry +=1 \n",
    "                    continue\n",
    "                face_loc = JSON_File[x][2]\n",
    "                cropped_image = crop_image(image, face_loc)\n",
    "                resized_image = resize_image(cropped_image)\n",
    "                X.append(resized_image)\n",
    "                Y.append(JSON_File[x][0]) # gender \n",
    "                Z.append(int(JSON_File[x][1])//5) # age\n",
    "                count +=1\n",
    "                \n",
    "                if(count % 1000 == 0):\n",
    "                    print('read one 1000')\n",
    "            except Exception as e:\n",
    "                print('ran into exception, skipping this photo entry, Error:', e)\n",
    "                continue\n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).astype('float32')\n",
    "    Y = keras.utils.to_categorical(Y)\n",
    "    Z = np.array(Z).astype('float32')\n",
    "    Z = keras.utils.to_categorical(Z, num_classes = 26)\n",
    "    print('read_images_by_file read', count, 'images')\n",
    "    print('read these files' , str(files),'There were ',corrupted_entry)\n",
    "    return X,Y,Z\n",
    "\n",
    "\n",
    "#store the model and the history and which data entries were processed \n",
    "def store_history_model(model, history, start, end, duration, historyFilelocation, model_name, dataSetName):\n",
    "    try:\n",
    "        try:\n",
    "            json_object = json.load(open(historyFilelocation))\n",
    "        except:\n",
    "            json_object = []\n",
    "\n",
    "        storage_file = open(historyFilelocation, 'w')\n",
    "\n",
    "        h5filename = str(start) + '-' + str(end)+ model_name + \"-\" + str(dataSetName)+ '.h5'\n",
    "        h5_location = \"./\" + model_name + \"/\" + h5filename;\n",
    "\n",
    "        model.save(h5_location);\n",
    "\n",
    "        json_object.append({\"h5Filename\": h5filename,\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"duration\": duration,\n",
    "                \"h5_location\": h5_location, \n",
    "                \"categorical_accuracy\": str(history.history['categorical_accuracy']),          \n",
    "                \"val_categorical_accuracy\": str(history.history['val_categorical_accuracy']),          \n",
    "                \"loss\": str(history.history['loss']),\n",
    "                \"val_loss\": str(history.history['val_loss'])\n",
    "                           })\n",
    "\n",
    "        json.dump(json_object, storage_file)\n",
    "        storage_file.close()\n",
    "    except Exception as e:\n",
    "        print('ran into exception while trying to store model after fitting for index ', start, ' to index ', end, ' , Error:', e)\n",
    "        return 0\n",
    "    \n",
    "    return 1\n",
    "def store_history_model_byFiles(model, history, files, duration, historyFilelocation, model_name, dataSetName):\n",
    "    try:\n",
    "        try:\n",
    "            json_object = json.load(open(historyFilelocation))\n",
    "        except:\n",
    "            json_object = []\n",
    "\n",
    "        storage_file = open(historyFilelocation, 'w')\n",
    "\n",
    "        h5filename = str(files)+ model_name + \"-\" + str(dataSetName)+ '.h5'\n",
    "        h5_location = \"./\" + model_name + \"/\" + h5filename;\n",
    "\n",
    "        model.save(h5_location);\n",
    "\n",
    "        json_object.append({\"h5Filename\": h5filename,\n",
    "                \"files\": str(files),\n",
    "                \"duration\": duration,\n",
    "                \"h5_location\": h5_location, \n",
    "                \"categorical_accuracy\": str(history.history['categorical_accuracy']),          \n",
    "                \"val_categorical_accuracy\": str(history.history['val_categorical_accuracy']),          \n",
    "                \"loss\": str(history.history['loss']),\n",
    "                \"val_loss\": str(history.history['val_loss'])\n",
    "                           })\n",
    "\n",
    "        json.dump(json_object, storage_file)\n",
    "        storage_file.close()\n",
    "    except Exception as e:\n",
    "        print('ran into exception while trying to store model Error:', e)\n",
    "        return 0\n",
    "    \n",
    "    return 1\n",
    "\n",
    "# pull the latest model checkpoint    \n",
    "def pull_latest_model(historyFilelocation):\n",
    "    try:\n",
    "        json_object = json.load(open(historyFilelocation))\n",
    "    except Exception as e:\n",
    "        print('could not get the latest model, Error:', e)\n",
    "        return 0\n",
    "    print('trying to load model from', json_object[len(json_object)-1]['h5_location'])\n",
    "    return keras.models.load_model(json_object[len(json_object)-1]['h5_location'])\n",
    "\n",
    "\n",
    "def fit_model(model, X, Y, num_epochs):\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy',\n",
    "                                            patience=1,\n",
    "                                           verbose=1)\n",
    "    batch_size = 40\n",
    "    epochs = num_epochs\n",
    "    validation_split = 0.2\n",
    "    history = model.fit(X, Y,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split = validation_split,\n",
    "                    callbacks = [callback])\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_gender_model(start, end, JSON_FILE, images_location, historyFile, dataSetName):\n",
    "    try:\n",
    "        print('Training gender model')\n",
    "        start_time = time.time()\n",
    "        X,Y,Z = read_images_gender_Age(start, end, JSON_FILE, images_location) #\"../imdb/\"\n",
    "        latest_gender_model =  pull_latest_model(historyFile)  # \"./genderHistory.json\"\n",
    "        if(latest_gender_model == 0):\n",
    "            print(\"couldn't find a stored model, generating a new one\")\n",
    "            latest_gender_model = gender_model(X,Y)\n",
    "        else:\n",
    "            print(\"Found previously stored model from \", historyFile)\n",
    "        \n",
    "        history = fit_model(latest_gender_model, X, Y, 1)\n",
    "        duration = (time.time() - start_time)\n",
    "        store_history_model(latest_gender_model,history,start,end,duration,historyFile,'gender',dataSetName)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print('ran into exception while training index ', start, ' to index ', end, ' did not train this set, Error:', e)\n",
    "        return 0\n",
    "        \n",
    "    return X,Y,Z\n",
    "\n",
    "def train_age_model(start, end, JSON_FILE, images_location, historyFile, dataSetName):\n",
    "    try:\n",
    "        print('Training age model')\n",
    "        start_time = time.time()\n",
    "        X,Y,Z = read_images_gender_Age(start, end, JSON_FILE, images_location) #\"../imdb/\"\n",
    "        latest_age_model =  pull_latest_model(historyFile)  # \"./genderHistory.json\"\n",
    "        if(latest_age_model == 0):\n",
    "            print(\"couldn't find a stored model, generating a new one\")\n",
    "            latest_age_model = age_model(X,Z)\n",
    "        else:\n",
    "            print(\"Found previously stored model from \", historyFile)\n",
    "        \n",
    "        history = fit_model(latest_age_model, X, Z, 2)\n",
    "        duration = (time.time() - start_time)\n",
    "        store_history_model(latest_age_model,history,start,end,duration,historyFile,'age',dataSetName)\n",
    "          \n",
    "    except Exception as e:\n",
    "        print('ran into exception while training index ', start, ' to index ', end, ' did not train this set, Error:', e)\n",
    "        return 0\n",
    "        \n",
    "    return X,Y,Z \n",
    "\n",
    "def train_gender_model_byfile(files, JSON_FILE, images_location, historyFile, dataSetName):\n",
    "    try:\n",
    "        print('Training gender model')\n",
    "        start_time = time.time()\n",
    "        X,Y,Z = read_images_byfile(files, JSON_FILE, images_location) #\"../imdb/\"\n",
    "        latest_gender_model =  pull_latest_model(historyFile)  # \"./genderHistory.json\"\n",
    "        if(latest_gender_model == 0):\n",
    "            print(\"couldn't find a stored model, generating a new one\")\n",
    "            latest_gender_model = gender_model(X,Y)\n",
    "        else:\n",
    "            print(\"Found previously stored model from \", historyFile)\n",
    "        \n",
    "        history = fit_model(latest_gender_model, X, Y, 1)\n",
    "        duration = (time.time() - start_time)\n",
    "        store_history_model_byFiles(latest_gender_model,history,files,duration,historyFile,'gender',dataSetName)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print('ran into exception while training did not train this set, Error:', e)\n",
    "        return 0\n",
    "        \n",
    "    return X,Y,Z \n",
    "\n",
    "def train_age_model_byfile(files, JSON_FILE, images_location, historyFile, dataSetName):\n",
    "    try:\n",
    "        print('Training age model')\n",
    "        start_time = time.time()\n",
    "        X,Y,Z = read_images_byfile(files, JSON_FILE, images_location) #\"../imdb/\"\n",
    "        latest_age_model =  pull_latest_model(historyFile)  # \"./genderHistory.json\"\n",
    "        if(latest_age_model == 0):\n",
    "            print(\"couldn't find a stored model, generating a new one\")\n",
    "            latest_age_model = age_model(X,Z)\n",
    "        else:\n",
    "            print(\"Found previously stored model from \", historyFile)\n",
    "            \n",
    "        history = fit_model(latest_age_model, X, Z, 2)\n",
    "        duration = (time.time() - start_time)\n",
    "        store_history_model_byFiles(latest_age_model,history,files,duration,historyFile,'age',dataSetName)\n",
    "          \n",
    "    except Exception as e:\n",
    "        print('ran into exception while training did not train this set, Error:', e)\n",
    "        return 0\n",
    "        \n",
    "    return X,Y,Z \n",
    "\n",
    "#fetch the last 20 percent from the imdb(368,475  --  92,119) & wiki(49,862 --- 12,466) data sets, and run model.predict and see what's the accuracy rate.     \n",
    "def test_model():\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "read one 1000\n",
      "Read from  0  to  44298 . There were  902\n",
      "trying to load model from ./gender/280000-320000gender-imdb.h5\n",
      "  2/868 [..............................] - ETA: 3:59 - loss: 0.3484 - categorical_accuracy: 0.8375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1282s vs `on_train_batch_end` time: 0.4245s). Check your callbacks.\n",
      "868/868 [==============================] - ETA: 0s - loss: 0.1753 - categorical_accuracy: 0.9372WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0076s vs `on_test_batch_end` time: 0.0935s). Check your callbacks.\n",
      "868/868 [==============================] - 521s 600ms/step - loss: 0.1753 - categorical_accuracy: 0.9372 - val_loss: 0.1525 - val_categorical_accuracy: 0.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 0\n",
    "end = 44298\n",
    "current_data_set = \"wiki\"\n",
    "gender_history_file = \"./genderHistory.json\"\n",
    "age_history_file = \"./ageHistory.json\"\n",
    "JSON_FILE = wiki_jsonFile\n",
    "X,Y,Z = read_images_gender_Age(start, end, JSON_FILE, \"../wiki/\")\n",
    "#curr_age_model = pull_latest_model(age_history_file)\n",
    "curr_gender_model = pull_latest_model(gender_history_file)\n",
    "\"\"\"\"\"\n",
    "if(curr_age_model == 0):\n",
    "    print(\"couldn't find a stored age model, generating a new one\")\n",
    "    curr_age_model = age_model(X,Z)\n",
    "history = fit_model(curr_age_model, X, Z, 1)\n",
    "store_history_model(curr_age_model,history,start,end,\"NA\",age_history_file,'age',current_data_set)\n",
    "\"\"\"\"\"                    \n",
    "if(curr_gender_model == 0):\n",
    "    print(\"couldn't find a stored gender model, generating a new one\")\n",
    "    curr_gender_model = gender_model(X,Y)\n",
    "history = fit_model(curr_gender_model, X, Y, 1)\n",
    "store_history_model(curr_gender_model,history,start,end,\"NA\",gender_history_file,'gender',current_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicitions  = model.predict(X[:,:,:,:])\n",
    "men_classified_as_women = []\n",
    "women_classified_as_men = []\n",
    "for x in range(len(Y)):\n",
    "    if(float(Y[x][1]) == 1.0 and float(predicitions[x][1]) < 0.5):\n",
    "        men_classified_as_women.append(x)\n",
    "        \n",
    "for x in range(len(Y)):\n",
    "    if(float(Y[x][0]) == 1.0 and float(predicitions[x][0]) < 0.5):\n",
    "        women_classified_as_men.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('men_classified_as_women ', len(men_classified_as_women))\n",
    "print('women_classified_as_men ',  len(women_classified_as_men))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(women_classified_as_men)):\n",
    "    print('showing Image at index -', women_classified_as_men[x])\n",
    "    print(Y[women_classified_as_men[x]])\n",
    "    print(predicitions[women_classified_as_men[x]])\n",
    "    plt.imshow(X[women_classified_as_men[x],:,:,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"00\",\"01\",\"02\",\"03\",\"\"]\n",
    "duration = \"NA\"\n",
    "current_data_set = \"wiki\"\n",
    "gender_history_file = \"./genderHistory.json\"\n",
    "age_history_file = \"./ageHistory.json\"\n",
    "X,Y,Z = read_images_byfile(files, wiki_jsonFile, \"../wiki/\")\n",
    "curr_age_model = pull_latest_model(age_history_file)\n",
    "curr_gender_model = pull_latest_model(gender_history_file)\n",
    "if(curr_age_model == 0):\n",
    "    print(\"couldn't find a stored age model, generating a new one\")\n",
    "    curr_age_model = age_model(X,Z)\n",
    "history = fit_model(curr_age_model, X, Z, 2)\n",
    "store_history_model_byFiles(curr_age_model,history,files,duration,age_history_file,'age',current_data_set)\n",
    "\n",
    "if(curr_gender_model == 0):\n",
    "    print(\"couldn't find a stored gender model, generating a new one\")\n",
    "    curr_gender_model = gender_model(X,Y)\n",
    "history = fit_model(curr_gender_model, X, Y, 2)\n",
    "store_history_model_byFiles(curr_gender_model,history,files,duration,gender_history_file,'gender',current_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing set ... to evaluate success \n",
    "A, B, C = read_images_gender_Age(320000, 398305, JSON_FILE, \"../wiki/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
