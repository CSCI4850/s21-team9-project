{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% PACKAGES INCLUDED HERE \n",
    "% DO NOT NEED TO CHANGE\n",
    "\\documentclass[conference]{IEEEtran}\n",
    "%\\IEEEoverridecommandlockouts\n",
    "% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.\n",
    "\\usepackage{cite}\n",
    "\\usepackage{amsmath,amssymb,amsfonts}\n",
    "\\usepackage{algorithmic}\n",
    "\\usepackage{graphicx}\n",
    "\\usepackage{textcomp}\n",
    "\\def\\BibTeX{{\\rm B\\kern-.05em{\\sc i\\kern-.025em b}\\kern-.08em\n",
    "    T\\kern-.1667em\\lower.7ex\\hbox{E}\\kern-.125emX}}\n",
    "\\begin{document}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% TITLE GOES HERE\n",
    "\n",
    "\\title{Image Processing: Identifying Age and Gender\\\\}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% AUTHOR NAMES GOES HERE\n",
    "\n",
    "\\makeatletter\n",
    "\\newcommand{\\linebreakand}{%\n",
    "    \\end{@IEEEauthorhalign}\n",
    "    \\hfill\\mbox{}\\par\n",
    "    \\mbox{}\\hfill\\begin{@IEEEauthorhalign}\n",
    "}\n",
    "\\makeatother\n",
    "\n",
    "\n",
    "\\author{\\IEEEauthorblockN{1\\textsuperscript{st} Gloria Abuka}\n",
    "\\IEEEauthorblockA{\\textit{Department of Computer Science} \\\\\n",
    "\\textit{Middle Tennessee State University}\\\\\n",
    "Murfreesboro, TN, USA \\\\\n",
    "gea2f@mtmail.mtsu.edu}\n",
    "\\and\n",
    "\\IEEEauthorblockN{2\\textsuperscript{nd} Rober Makram}\n",
    "\\IEEEauthorblockA{\\textit{Department of Computer Science} \\\\\n",
    "\\textit{Middle Tennessee State University}\\\\\n",
    "Murfreesboro, TN, USA \\\\\n",
    "rbm3d@mtmail.mtsu.edu}\n",
    "\\and\n",
    "\\IEEEauthorblockN{3\\textsuperscript{rd} Kirolous Shihataa}\n",
    "\\IEEEauthorblockA{\\textit{Department of Computer Science} \\\\\n",
    "\\textit{Middle Tennessee State University}\\\\\n",
    "Murfreesboro, TN, USA \\\\\n",
    "krs6q@mtmail.mtsu.edu}\n",
    "\\linebreakand\n",
    "\\IEEEauthorblockN{4\\textsuperscript{th} Jessica Wijaya}\n",
    "\\IEEEauthorblockA{\\textit{Department of Computer Science} \\\\\n",
    "\\textit{Middle Tennessee State University}\\\\\n",
    "Murfreesboro, TN, USA \\\\\n",
    "jcw8h@mtmail.mtsu.edu}\n",
    "\\and\n",
    "\\IEEEauthorblockN{5\\textsuperscript{th} Hannah Williams}\n",
    "\\IEEEauthorblockA{\\textit{Department of Computer Science} \\\\\n",
    "\\textit{Middle Tennessee State University}\\\\\n",
    "Murfreesboro, TN, USA \\\\\n",
    "hnw2y@mtmail.mtsu.edu}\n",
    "}\n",
    "\n",
    "\\maketitle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% ABSTRACT \n",
    "\n",
    "\\begin{abstract}\n",
    "The importance of facial recognition specifically in age and gender classification in today’s world cannot be overemphasized as the demand for the applications that make use of these systems have been on the rise lately. In this paper, we examine a few existing models built of the convolutional neural network architecture, their level of success and we tried to improve on them by building our model based on a pre-trained Xception model with rich datasets for both age and gender classifications to better enhance the performance. The efficiency of our model is evident from the results obtained after training of the IMDB-WIKI datasets. A higher level of accuracy was achieved for the gender classifications than the age classifications.\n",
    "\\end{abstract}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% KEYWORDS\n",
    "\n",
    "\\begin{IEEEkeywords}\n",
    "component, formatting, style, styling, insert\n",
    "\\end{IEEEkeywords}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% INTRODUCTION SECTION\n",
    "\\section{Introduction}\n",
    "\n",
    "Facial recognition has generally gained much popularity over the years for the important role it plays across various industries. Its applications are greatly in use in the security, medical, and target-advertising industries. In 2020, the global pandemic changed the world as we knew it, and this brought about the need to find a way to reduce physical contact while maintaining usual day to day interactions. Facial recognition also plays a vital role in that aspect. The ever-growing need for applications of age and gender classification through facial images has attracted the attention of many researchers over the years.  \n",
    "\n",
    "\n",
    "\n",
    "Many previous studies have been conducted to create neural networks that can obtain information from facial images including a person’s age, gender, ethnicity, etc.  The goal of our research project is to train two neural nets, one that can classify images of people by their gender and one to determine the age of the individual. The IMDB-WIKI dataset will be used to train the models. This dataset contains over 500,000 face images that were web scraped from IMDb and Wikipedia \\cite{b4}. Additionally, only the images containing a single person will be used as input and the data will be preprocessed to prepare the images for the neural net. We will be using transfer learning to build upon pretrained models and attempt to improve the performance of these networks. \n",
    "\n",
    "\n",
    "\\subsection{History}\n",
    "\n",
    "Talking about image processing and computer vision, convolutional neural networks (CNN) are recognized as the foundation on which such models thrive. The idea of the CNN started with the discovery of David Hubel and Torsten Wiesel back in 1959. They discovered the idea of simple cells and complex cells in the human cortex, these cells are used in pattern recognition \\cite{b3}. \n",
    "\n",
    "While a simple cell responds to edges and bars of a particular orientation, a complex cell responds to those edges and bars even when they are shifted in different positions around the scene. This property is known as “spatial invariance”. Spatial invariance is achieved by summing the output of several simple cells that prefer the same orientation \\cite{b3}. This concept forms the basis of convolutional neural networks which is adopted for our age and gender model in this paper.  \n",
    "\n",
    "A core contribution to this field was made in the 1980s by Dr. Kunihiko Fukushima. His discovery was inspired by the work of Hubel and Wiesel. He proposed the concept of the “neocognitron,” this model consists of the S-cells and C-cells. The S-cells are like the simple cell while C-cells are like the complex cells. The major idea of this model was to capture the simple-complex and turn it into a computational model for pattern recognition \\cite{b3}.  \n",
    "\n",
    "The first model built on the concept of CNNs was in the 1990s by Yann Lecun who was inspired by the previous research. Lecun used a CNN model trained on the popular MNIST dataset to recognize handwritten digits 0-9. CNNs gained the huge popularity it has today in 2012 when a CNN called AlexNet achieved a great deal of success labelling pictures in the imageNet challenge \\cite{b3}. Convolutional neural networks have come a long way over the past decades and the future looks even brighter.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% BACKGROUND SECTION\n",
    "\\section{Background}\n",
    "\n",
    "Of course, many developers have built models to attack the problem of age and gender prediction using various techniques. A research group at the Open University of Israel \\cite{b2} created deep-convolutional neural networks to attempt to get an improved accuracy in identifying an individual’s age and gender from an image of their face as compared to current models at the time of the article in 2015. Their network was composed of just three moderate sized convolutional layers, two relatively small dense layers, and an output layer. This model was much smaller than other models in the past that were built to solve the same problem. The group’s reason for keeping it small is that they did not want to risk overfitting the model to the training data. The group utilized units with ReLU activation functions and also used dropout layers to make sure the network was being trained as evenly as possible. Their final net could identify the gender typically around 86% of the time and the age within one year around 84% of the time from an image the net had not trained on. The net typically had a hard time identifying the gender of young children because there would tend to be less identifying gender features present because of their age.  \n",
    "\n",
    "In a similar study that aimed to improve the accuracy of age group and gender predictions of real-world faces, researchers from the University of Kwazulu-Natal created a convolutional neural net with the goal of handling the many variations present in unfiltered images \\cite{b1}. The neural net contains four convolutional layers that are each followed by a dense layer with the ReLU activation function, a batch normalization layer, max-pooling, and a dropout layer. The softmax function is used for the output layer. The model was trained using the IMDb, MORPH-II, and OIU-Adience datasets. To achieve a higher accuracy in making predictions on unfiltered facial images, they implemented an image preprocessing algorithm to prepare the images being fed into the network. Their results yielded some success with an accuracy of about 96% for gender predictions and roughly 83% for age group classifications. The images that were incorrectly classified typically had issues such as low resolution and poor lighting. \n",
    "\n",
    "For this project, we originally aimed to create our own models that could achieve a reasonable accuracy in predicting age and gender from facial images. Although the initial goal was to create two networks from scratch for age and gender classification, we ended up using transfer learning to add layers on to the Xception network in order to attain better results. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% METHODS SECTION\n",
    "\\section{Methods}\n",
    "\n",
    "Like most convolutional neural networks that compute information from images, our workflow requires for the input to be preprocessed before being fed into the model. The data set we are using consists of thousands of images of people’s faces, as well as MATLAB files that contain the meta data relating of each image. The dataset includes some variation such as images with multiple people, images with no people, and some noise from mislabeled data. The MATLAB files have a lot of information about the person in each image like their gender and their birthdate or birthyear as well as the date of when the photo was taken. Additionally, the metadata includes the coordinates for each face located within an image. These are the parts of the metadata that we processed and utilized for the training of the networks. \n",
    "\n",
    "In order to prepare the data for training, the metadata of the images also had to be processed. The data contains information of an individual’s birthdate and the date that the image was taken. From this, we wrote some functions to calculate the age, in years, of the depicted person. Additionally, we extracted the gender, and face locations from the IMDb MATLAB file. \n",
    "\n",
    "Furthermore, to process the images themselves for training, the image is first cropped using the coordinates in the meta data that specify the face location. This will eliminate potential noise from the background and make the face the main focus of the image. Then the image is resized to be 200 by 200 pixels. Also, when the images are read in before training, they are checked for corruption and skipped over if corrupted. The images that contained no faces were similarly discarded. \n",
    "\n",
    "After the preprocessing, we discovered that 129 of the IMDd dataset were bad but the wiki data set had no bad images. We deleted the corrupted images from the data set and moved onto building our models.  \n",
    "\n",
    "Our model for gender predictions begins with the pretrained Xception model. We tried various ways to avoid using a pretrained net such as adding a variety of convolutional, dense, and max pooling layers of various sizes, but ultimately the only method that succeeded in greatly increasing the accuracy of the output was to use a pretrained net as a base model and to add layers on top of it. The top of the Xception model was left off and the output was rerouted into the new layers added on top. After the base, our model consists of a global average pooling layer in order to take the average of each feature map of an image. After that we have a dense layer with 128 units with the ReLU activation function. Lastly, we have another dense layer that is the size of the output with the softmax activation function to help deal effectively with the classification problem. We then compile our model with the Adam optimizer and categorical cross entropy. We use categorical accuracy as the metric of the model.  \n",
    "\n",
    "The age model is set up in a largely similar way. It is also built on top of the Xception network with a pooling layer, a dense layer with 128 units using the ReLU activation function, and the output layer that uses softmax. Together, these two models make up what we used to train the model to predict the age and gender of a person in each image.  \n",
    "\n",
    "When it came to putting our models to the test, we used some images of our own to see what the model would predict. Outside images, of course, do not come with the comprehensive metadata that the IMDb WIKI dataset had. We used a python facial recognition called face-recognition [CITE] library to detect a face or set of faces in an image. If no face could be found by the software, we would not use that image. Once the face location or locations were returned, an image would be generated that is cropped to just the individual’s face or generate a set of images, one with each person’s face in the whole photo. This would eliminate any outside noise that may affect the predictions. These modified images would then be run through the models. We then could output the top decisions of age group and gender as well as the percentage likelihood that the person in the photo was a male or a female and the top three age group predictions made by the net.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% RESULTS SECTION\n",
    "\\section{Results}\n",
    "\n",
    "After extensive training, both models reached sufficient accuracies. Around 360,000 images were trained on our model. To make this process easier, the images were divided into groups of 40,000. The convolution net was trained with each group and the weights and history was saved periodically to keep track of the progress and accuracy.  \n",
    "\n",
    "% IMAGE INSERT\n",
    "\\begin{figure}[htbp]\n",
    "\\centerline{\\includegraphics[width=\\linewidth]{./Pictures/Gender.PNG}}\n",
    "\\caption{Accuracy And Loss Graph Of The Gender Model}\n",
    "\\label{fig1}\n",
    "\\end{figure}\n",
    "\n",
    "Figure 1 shows the loss graph of the model used to determine gender. Our model did well classifying images it had never seen with an accuracy of up to 82\\%. We started at an accuracy of 37\\% which we were able to drive up to 82\\% after training. \n",
    "\n",
    "% IMAGE INSERT\n",
    "\\begin{figure}[htbp]\n",
    "\\centerline{\\includegraphics[width=\\linewidth]{./Pictures/Age.PNG}}\n",
    "\\caption{Accuracy And Loss Graph Of The Age Model}\n",
    "\\label{fig2}\n",
    "\\end{figure}\n",
    "\n",
    "Our age prediction model is designed to predict the age group rather than the specific age of an individual. The range of ages goes from 0 to 130 years in groups of 5 which makes it a total of 26 different age groups (0-4, 5-9, 10-14, 15-19...). We encountered difficulties in reaching our expected level of accuracy because of the nature of the classification it is intended to do. We began at an accuracy of 12\\% and increased it to 31\\% after all the training was done. In the graph however, you can observe a dip in accuracy at the very end. This could be because either the last set of data was particularly noisy or a sign of possible overfitting. Because we were saving the model after each set of 40,000 images were trained, we decided to do early stopping and simply use the previous set of weights that were calculated before it was trained on the last group of images. \n",
    "\n",
    "It’s also worth noting that an age is only considered correct if it falls perfectly in the age range group it’s classified as, and everything else is considered completely wrong. The accuracy percentage may come off a bit harsher than it should because of this reason. For example, say a 14-year-old gets placed in the 15-19 category by the network. This is a wrong classification made by the network of course, but let’s say the network classified the same 14-year-old in the 75-79 category. That is marked wrong as well, but obviously one of those classifications is much closer than the other. The accuracy metric does not see that though, and marks both incorrect classifications as equally bad and wrong.  \n",
    "\n",
    "% IMAGE INSERT\n",
    "\\begin{figure}[htbp]\n",
    "\\centerline{\\includegraphics[width=\\linewidth]{\"./Pictures/3 Predictions.png\"}}\n",
    "\\caption{Some Example Calculations Made By The Models}\n",
    "\\label{fig3}\n",
    "\\end{figure}\n",
    "\n",
    "Figure 3 shows what the network outputs when classifying an image that it has never seen before. It identifies a face or set of faces if any are recognizable using the imported facial recognition tools. Here you can see a group of three individuals. Each person’s face is cropped off to their own individual picture and each photo is run through the networks. Then the results of the age group and gender prediction is outputted as well as the percentage likelihood of the male and female classifications and the top three guesses for age group.  \n",
    "\n",
    "% IMAGE INSERT\n",
    "\\begin{figure}[htbp]\n",
    "\\centerline{\\includegraphics[width=\\linewidth]{\"./Pictures/Correct Classification.png\"}}\n",
    "\\caption{Correct Classification Made By The Network}\n",
    "\\label{fig4}\n",
    "\\end{figure}\n",
    "\n",
    "Figure 4 shows an individual (actor Tom Hardy) whose gender was predicted correctly as male by the gender identifying network. \n",
    "\n",
    "% IMAGE INSERT\n",
    "\\begin{figure}[htbp]\n",
    "\\centerline{\\includegraphics[width=\\linewidth]{\"./Pictures/Wrong Classification.png\"}}\n",
    "\\caption{Incorrect Classification Made By The Network}\n",
    "\\label{fig5}\n",
    "\\end{figure}\n",
    "\n",
    "Figure 5 shows the same individual (actor Tom Hardy) whose gender was predicted incorrectly as female by the gender identifying net. Any number of things could have led to this wrong decision made by the network such as amount of facial hair, bone structure, the size of certain parts of the face, the angle the image was taken at, the lighting, and so on. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% DISCUSSION SECTION\n",
    "\\section{Discussion and Conclusion}\n",
    "\n",
    "Our model sometimes misclassified images due to factors like poor quality, low brightness, or the angle at which the picture was taken. An image that is grainy or low quality may not capture all the details that the model needs to do an accurate prediction. Some of the misclassifications also were due to the incorrect class labels present in the metadata. \n",
    "\n",
    "Over the course of this project, we encountered some challenges that made us reexamine our approach to creating a neural network that could predict age and gender from an image. The original goal had been to design and train a model from scratch that had some differences from the ones previously created. However, we had difficulties in training these models to reach a reasonable accuracy and decided to instead add layers on top of a pretrained base model. This yielded more accurate results for both the gender and age predictions.  \n",
    "\n",
    "Additionally, the training of these networks took a considerable amount of time with the large number of images present in the dataset. Some of the training also had to be repeated after it was discovered that the dataset contained images that has no faces in them since this would add unintended noise and lower the accuracy of the model. \n",
    "\n",
    "In conclusion, ... "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% REFERENCES\n",
    "% THIS IS CREATED AUTOMATICALLY\n",
    "\\bibliographystyle{IEEEtran}\n",
    "\\bibliography{References} % change if another name is used for References file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\end{document}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
