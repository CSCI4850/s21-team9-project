{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% PACKAGES INCLUDED HERE \n",
    "% DO NOT NEED TO CHANGE\n",
    "\\documentclass[conference]{IEEEtran}\n",
    "%\\IEEEoverridecommandlockouts\n",
    "% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.\n",
    "\\usepackage{cite}\n",
    "\\usepackage{amsmath,amssymb,amsfonts}\n",
    "\\usepackage{algorithmic}\n",
    "\\usepackage{graphicx}\n",
    "\\usepackage{textcomp}\n",
    "\\def\\BibTeX{{\\rm B\\kern-.05em{\\sc i\\kern-.025em b}\\kern-.08em\n",
    "    T\\kern-.1667em\\lower.7ex\\hbox{E}\\kern-.125emX}}\n",
    "\\begin{document}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% TITLE GOES HERE\n",
    "\n",
    "\\title{Image Processing: Identifying Age and Gender\\\\}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% AUTHOR NAMES GOES HERE\n",
    "\n",
    "\\makeatletter\n",
    "\\newcommand{\\linebreakand}{%\n",
    "    \\end{@IEEEauthorhalign}\n",
    "    \\hfill\\mbox{}\\par\n",
    "    \\mbox{}\\hfill\\begin{@IEEEauthorhalign}\n",
    "}\n",
    "\\makeatother\n",
    "\n",
    "\n",
    "\\author{\\IEEEauthorblockN{1\\textsuperscript{st} Gloria Abuka}\n",
    "\\IEEEauthorblockA{\\textit{Department of Computer Science} \\\\\n",
    "\\textit{Middle Tennessee State University}\\\\\n",
    "Murfreesboro, TN, USA \\\\\n",
    "gea2f@mtmail.mtsu.edu}\n",
    "\\and\n",
    "\\IEEEauthorblockN{2\\textsuperscript{nd} Rober Makram}\n",
    "\\IEEEauthorblockA{\\textit{Department of Computer Science} \\\\\n",
    "\\textit{Middle Tennessee State University}\\\\\n",
    "Murfreesboro, TN, USA \\\\\n",
    "rbm3d@mtmail.mtsu.edu}\n",
    "\\and\n",
    "\\IEEEauthorblockN{3\\textsuperscript{rd} Kirolous Shihataa}\n",
    "\\IEEEauthorblockA{\\textit{Department of Computer Science} \\\\\n",
    "\\textit{Middle Tennessee State University}\\\\\n",
    "Murfreesboro, TN, USA \\\\\n",
    "krs6q@mtmail.mtsu.edu}\n",
    "\\linebreakand\n",
    "\\IEEEauthorblockN{4\\textsuperscript{th} Jessica Wijaya}\n",
    "\\IEEEauthorblockA{\\textit{Department of Computer Science} \\\\\n",
    "\\textit{Middle Tennessee State University}\\\\\n",
    "Murfreesboro, TN, USA \\\\\n",
    "jcw8h@mtmail.mtsu.edu}\n",
    "\\and\n",
    "\\IEEEauthorblockN{5\\textsuperscript{th} Hannah Williams}\n",
    "\\IEEEauthorblockA{\\textit{Department of Computer Science} \\\\\n",
    "\\textit{Middle Tennessee State University}\\\\\n",
    "Murfreesboro, TN, USA \\\\\n",
    "hnw2y@mtmail.mtsu.edu}\n",
    "}\n",
    "\n",
    "\\maketitle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% ABSTRACT \n",
    "\n",
    "\\begin{abstract}\n",
    "This document is a model and instructions for \\LaTeX.\n",
    "This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes, \n",
    "or Math in Paper Title or Abstract.\n",
    "\\end{abstract}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% KEYWORDS\n",
    "\n",
    "\\begin{IEEEkeywords}\n",
    "component, formatting, style, styling, insert\n",
    "\\end{IEEEkeywords}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% INTRODUCTION SECTION\n",
    "\\section{Introduction}\n",
    "\n",
    "Facial recognition generally has gained much popularity over the years for the important role it plays across various industries. Its applications are greatly in use in the security, medical, and target-advertising industries. In 2020, the global pandemic changed the world as we knew it, and this brought about the need to find a way to reduce physical contact while maintaining usual day to day interactions. Facial recognition also plays a vital role in that aspect. The ever-growing need for applications of age and gender classification through facial images has attracted the attention of many researchers over the years.  \n",
    "\n",
    "Many previous studies have been conducted to create neural networks that can obtain information from facial images including a person’s age, gender, ethnicity, etc.  The goal of our research project is to create two neural nets, one that can classify images of people by their gender and one to determine the age of the individual. The IMDB-WIKI dataset will be used to train the models. This dataset contains over 500,000 face images that were web scraped from IMDb and Wikipedia (CITE imdb-wiki). Additionally, only the images containing a single person will be used as input and the data will be preprocessed to prepare the images for the neural net. (Add brief summary of the layers in the NN) \n",
    "\n",
    "\\subsection{History}\n",
    "\n",
    "Talking about image processing and computer vision, Convolutional Neural Networks (CNN) is recognized as the foundation on which such models thrive. The idea of CNN started with the discovery of David Hubel and Torsten Wisel back in 1959. They discovered the idea of simple cells and complex cells in the human cortex, these cells are used in pattern recognition. \n",
    "\n",
    "While a simple cell responds to edges and bars of a particular orientation, a complex cell responds to those edges and bars even when they are shifted in different positions around the scene. This property is known as “Spatial invariance”. Spatial invariance is achieved by summing the output of several simple cells that prefer the same orientation. This concept forms the basis of Convolutional Neural Networks which is adopted for our age and gender model in this paper.  \n",
    "\n",
    "A core contribution to this field was made in the 1980s by Dr. Kunihiko Fukushima. His discovery was inspired by the work of Hubel and wisel. He proposed the concept of “neocognition,” this model consist of the S-cells and C-cells. The S-cells are like the simple cell while C-cells are like the complex cells. The major idea of this model was to capture the simple-complex and turn it into a computational model for pattern recognition.  \n",
    "\n",
    "The first model built on the concept of CNN was in the 1990s inspired by the previous research above was done by Yann Lecun. Lecun used a CNN model trained on the popular MNIST dataset to recognize handwritten digits 0-9.  \n",
    "\n",
    "CNN gained the huge popularity it has today in 2012 when a CNN called AlexNet achieved a great deal of success labelling pictures in the imageNet challenge.  \n",
    "\n",
    "Convolutional Neural Networks have come a long way over the past decades and the future looks even brighter.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% BACKGROUND SECTION\n",
    "\\section{Background}\n",
    "\n",
    "\n",
    "Of course, many developers have built models to attack this problem using various techniques. A research group at the Open University of Israel \\cite{b2} created deep-convolutional neural networks to attempt getting an improved accuracy in identifying an individual’s age and gender from an image of their face as compared to current models at the time of the article in 2015. Their network was composed of just three moderate sized convolutional layers, two relatively small dense layers, and an output layer. This model was much smaller than other models in the past that were built to solve the same problem. The group’s reason for keeping it small is that they did not want to risk overfitting the model to the training data. The group utilized units with ReLU activation functions and also used dropout layers to make sure the network was being trained as evenly as possible. Their final net could identify the gender typically around 86% of the time and the age within one year around 84% of the time from an image the net had not trained on. The net typically had a hard time identifying the gender of young children because there would tend to be less identifying gender features present because of their age.  \n",
    "\n",
    "In a similar study that aimed to improve the accuracy of age group and gender predictions of real-world faces, researchers from the University of Kwazulu-Natal created a convolutional neural net with the goal of handling the many variations present in unfiltered images \\cite{b1}. The neural net consists of four convolutional layers that are each followed by a dense layer with the ReLU activation function, a batch normalization layer, max-pooling, and a dropout layer. The softmax function is used for the output layer. The model was trained using the IMDb, MORPH-II, and OIU-Adience datasets. To achieve a higher accuracy in making predictions on unfiltered facial images, they implemented an image preprocessing algorithm to prepare the images being fed into the network. Their results yielded some success with an accuracy of about 96% for gender predictions and roughly 83% for age group classifications. The images that were incorrectly classified typically had issues such as low resolution and poor lighting. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% METHODS SECTION\n",
    "\\section{Methods}\n",
    "\n",
    "Like most convolutional neural networks that compute information from images, our workflow requires the input be preprocessed before being fed into the model. The data set we are using consists of thousands of images of people’s faces, as well as MATLAB files that contain the meta data relating to each image. The MATLAB files have a lot of information about the person in each image like their gender and their birthdate or birthyear as well as when the photo was taken. We used this information to determine what each individual’s age was at the time of the photo. This is the data that we trained the age predicting portion of our network on.  \n",
    "\n",
    "In order to prepare the data for training, the metadata of the images also had to be processed. The data contains information of an individual’s birthdate and the date that the image was taken. From this, we wrote some functions to calculate the age, in years, of the depicted person. Additionally, we extracted the gender, and face locations from the IMDb MATLAB file. \n",
    "\n",
    "In order to process the images themselves for training, the image is first cropped using the coordinates that specify the face location. This will eliminate potential noise from the background and make the face the main focus of the image. Then the image is resized to be 200 by 200 pixels. Also, when the images are read in before training, they are checked for corruption and skipped over if corrupted. \n",
    "\n",
    "After the preprocessing, we discovered that 129 of the IMDd dataset were bad but the wiki data set had no bad image.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% RESULTS SECTION\n",
    "\\section{Results}\n",
    "\n",
    "Start typing here."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% DISCUSSION SECTION\n",
    "\\section{Discussion}\n",
    "\n",
    "Start typing here."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% REFERENCES\n",
    "% THIS IS CREATED AUTOMATICALLY\n",
    "\\bibliographystyle{IEEEtran}\n",
    "\\bibliography{References} % change if another name is used for References file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\end{document}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
